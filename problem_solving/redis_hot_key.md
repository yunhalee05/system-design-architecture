# Redis 트래픽 급증과 Redis 핫키 


## 문제 
### 상황
- 대규모 멤버십 서비스를 운영 중인 서버가 있다.
- Redis를 캐시로 사용하고 있고, 특정 API(/user/{id}/benefits)가 자주 호출된다.
- 사용자 ID별로 Redis에 user:benefit:{id} 형태로 데이터를 저장한다.
- 어느 날 특정 마케팅 캠페인으로 인해 일부 사용자(예: influencer) 에 대한 요청이 폭증하면서 Redis CPU 사용률이 급상승했고, API 응답 지연이 발생했다.
- 로그를 보면 DB 부하가 아니라 Redis에서 병목이 일어나고 있다.
- Redis는 단일 스레드 구조로, 특정 키에 대한 요청 집중이 전체 성능 저하로 이어지고 있다.

### 과제
- 문제를 정확히 정의하고, 왜 이런 현상이 Redis 구조상 발생했는지 설명하라.
- 단기적(즉각적인 대응) + 중장기적(근본적 설계 개선) 대응 방안을 모두 제시하라.
- 해결 후, 같은 문제가 재발하지 않도록 모니터링 포인트와 지표 설계까지 포함하라.




## 해결 
### 문제 정의 
- 일부 키에 대한 과도한 요청 집중으로 Redis 인스턴스 단일 스레드 병목 발생

Redis는 단일 스레드 이벤트 루프 모델이기 때문에, 동시에 10개의 클라이언트가 GET user:benefit:1234 를 요청하더라도 내부적으로는 순차적으로 처리된다. 결국 CPU는 1개의 코어에서 한 키에 대한 요청을 계속 처리하므로
특정 키 하나가 전체 성능을 잡아먹는 Hot Key 현상이 발생한다.

### 단기적 해결 방안 
| 목표         | 방안                      | 설명                                                                                             |
| ---------- | ----------------------- | ---------------------------------------------------------------------------------------------- |
| **트래픽 완화** | API Gateway / CDN 캐시 적용 | 특정 키(`user:benefit:1234`)를 정적 JSON 캐시 형태로 CloudFront, Nginx 캐시 등에 저장                           |
| **핫키 보호**  | Redis 앞단에 로컬 캐시 계층 추가   | Caffeine, Guava, Spring Cache 등으로 동일 요청을 애플리케이션 수준에서 흡수                                        |
| **임시 우회**  | 핫키 감지 후 다른 Redis로 리디렉션  | 특정 키가 과도하게 요청될 경우 임시로 별도 인스턴스에 저장 후 라우팅 (e.g. Redisson local cache or multi-instance redirect) |
| **읽기 완화**  | TTL을 짧게 두고 캐시 갱신 주기 조절  | 읽기 요청 중 일부만 Redis에 접근하도록 rate limit 적용                                                         |


### 중장기적 해결 방안 
#### 1. 샤딩 전략
예: user:benefit:1234:bucket:{0~n} 형태로 여러 키에 나누어 저장

읽기 시 랜덤 버킷에서 읽고, 쓰기 시에는 모든 버킷 갱신

trade-off: 업데이트 비용 상승 vs 읽기 병목 완화

샤딩 기준: hash(userId) % n or UUID fragment
→ Hot Key 발생 확률을 통계적으로 분산

#### 2. Hot Key 분리용 Proxy Layer 구축

자체 Redis Proxy (예: Twemproxy, Dynomite, Codis)로 키 기반 분산 라우팅

특정 키가 과도하게 집중되면 Proxy Layer가 분산 라우팅을 조정

#### 3. 데이터 중복 캐싱 (Multi-tier Cache)

L1: 애플리케이션 JVM 메모리

L2: Redis

L3: CDN
→ Hot Key 요청을 L1/L3에서 대부분 소화하도록 구성

#### 4. Async Cache Warm-up + Lazy Update

실시간으로 갱신하지 않고, 백그라운드 큐로 업데이트

TTL 만료 전 미리 Warm-up (soft TTL 기법)

읽기 요청이 폭주해도 Redis 부하가 급격히 늘지 않음
