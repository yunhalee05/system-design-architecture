# HashMap 구조 관련 내용 정리 (feat. Redis) 

## Q1. HashMap vs Hashtable 의 차이점은?
> 해시 맵의 경우 동기화를 방지하지 않는 맵이면 HashTable의 경우 모든 메서드가 synchronized 처리가 되어있어 동시성을 방지하는 자료구조 입니다.

| 항목             | HashMap                                 | Hashtable                 |
| -------------- | --------------------------------------- | ------------------------- |
| **스레드 안전성**    | ❌ (스레드 안전하지 않음)                         | ✅ (모든 메서드가 synchronized)  |
| **동기화 방식**     | 필요 시 `Collections.synchronizedMap()` 사용 | 기본적으로 동기화되어 있음            |
| **null 허용 여부** | key에 1개, value에 여러 개 허용                 | key와 value 모두 `null` 허용 ❌ |
| **성능**         | 동기화 안 되어 있어서 빠름                         | 동기화로 인해 느림                |
| **사용 권장**      | 단일 스레드 환경에서 주로 사용                       | 과거 코드에서만 사용됨 (요즘은 거의 안 씀) |


---

## Q2. Redis는 기본적으로 단일 스레드로 동작하는데, Redis 내부에서 해시(Hash type)가 저장되는 자료구조는 어떤 방식으로 구성되어 있을까요? (예: 해시 필드 수나 메모리 사용량에 따라 어떤 방식으로 바뀌는지 설명해 주세요.)
> 레디스의 hash 자료형은 내부적으로 ziplist 방식으로 되어있지만, 어느정도 크기가 넘어가면 hash table 구조로 변경됩니다.

| 방식                                | 설명                                                 |
| --------------------------------- | -------------------------------------------------- |
| **ziplist (또는 최신 버전에선 listpack)** | 해시 필드 수가 적고, 각 필드와 값이 작을 때 사용되는 **메모리 절약형 구조**입니다. |
| **hashtable (dict)**              | 일정 기준을 초과하면 일반적인 해시테이블(dict) 구조로 변환됩니다.            |

---

## Q3. 해시 테이블에서 해시 충돌(collision)을 처리하는 대표적인 방법 두 가지를 설명해 주세요.
> 해시 충돌이 발생했을때 체이닝 방식과 슬롯 방식으로 문제를 해결할 수 있습니다.  
> 체이닝 방식의 경우 고정된 크기에 연결리스트 방식으로 값을 연결해서 사용하는 방식으로 메모리 사용이 적지만 값이 많아질수록 조회 성능이 떨어질 수 있고,  
> 슬롯 방식은 비어있는 슬롯에 값을 채우는 방식으로 메모리 사용이 많을 수 있지만 조회 성능이 빠릅니다.

| 방식                                  | 설명                                                       | 장점                           | 단점                          |
| ----------------------------------- | -------------------------------------------------------- | ---------------------------- | --------------------------- |
| **1. Chaining (Separate Chaining)** | 같은 해시 인덱스에 여러 개의 값을 **리스트로 연결**해서 저장                     | 충돌 처리 간단, 해시 테이블이 꽉 차도 저장 가능 | 공간 추가 필요, 리스트가 길어지면 탐색 느림   |
| **2. Open Addressing (개방 주소법)**     | 충돌 발생 시 **다음 빈 슬롯을 찾아 저장** (예: Linear/Quadratic Probing) | 메모리를 덜 사용                    | 테이블이 꽉 차면 성능 저하, 삭제 처리 까다로움 |


#### 🔹 1. Separate Chaining (체이닝)
- 개념: 같은 해시 버킷에 여러 항목이 들어갈 경우 LinkedList, Tree (Java 8 이후) 등으로 버킷마다 리스트를 구성해 충돌 처리
- 장점:
  - 테이블 크기보다 많은 요소도 저장 가능
  - 해시 테이블 확장(rehashing) 없이도 충돌 처리 가능
- 단점:
  - 충돌이 많아지면 탐색 시간 O(n) (리스트 길이에 비례)
  - 캐시 효율이 떨어짐 (연속 메모리가 아니기 때문)
#### 🔹 2. Open Addressing (개방 주소법)
- 개념: 충돌이 발생하면 빈 슬롯을 찾아 저장 (선형 탐사, 이차 탐사, 이중 해싱 등)
- 장점:
  - 연속된 메모리에 저장 → 캐시 효율 우수
  - 포인터가 없어 메모리 절약
- 단점:
  - 테이블이 가득 차기 쉬움 → 로드 팩터가 낮아야 성능 유지
  - 삭제 처리 복잡 (deleted marker 필요)
  - 클러스터링 현상 발생 가능

### 참고) Consistent Hashing
Consistent Hashing은?

안정 해시(Consistent Hashing)는 일반 해시 테이블 내부 충돌 해결 방식은 아니고, 보통 다음과 같은 경우에 쓰입니다:
- 캐시 서버 분산 (예: Redis Cluster, Memcached)
- 노드 수가 동적으로 변하는 분산 시스템

이런 환경에서 key % n 방식은 노드 수 변화에 민감하므로, 키 재배치 부담을 줄이기 위해 Consistent Hashing + 가상 노드 전략을 사용합니다. 

---

## Q4. Redis Cluster에서 Consistent Hashing을 쓰지 않고 Hash Slot 방식(0~16383)을 사용하는 이유는 뭘까요? Consistent Hashing 대신 Hash Slot 방식을 택한 이유를 설명해 주세요.
> Redis Cluster는 정확히 몇 개의 hash slot을 어떤 노드가 가졌는지 추적함으로써, 데이터 재배치가 빠르고 예측 가능하게 만들기 위해 Consistent Hashing 대신 Hash Slot 방식을 선택했습니다.
- Redis Cluster는 키 공간을 16,384개의 고정된 Hash Slot으로 나누고, 이 슬롯들을 노드에 분배하는 방식을 사용
- Consistent Hashing을 쓰지 않는 이유:
  - 슬롯 단위로 분산하면 → 노드 간 데이터 분배, 이동이 더 직관적이고, 모든 키 공간을 일정하게 관리할 수 있음.
  - Consistent Hashing은 해시 링 구조 상에서 key 이동은 최소화되지만, 각 노드가 자신이 소유한 범위의 상태를 완벽하게 알기 어려움.
  - 반면, Redis의 Hash Slot 구조는:
  - 각 노드가 자신이 가진 슬롯 범위를 정확히 알 수 있음
  - 슬롯 단위로 키 이동이 가능해 Resharding, Failover 처리 시 명확하고 안정적임

| 이유                             | 설명                                                                            |
| ------------------------------ | ----------------------------------------------------------------------------- |
| **키 → 슬롯 → 노드 구조로 매핑이 단순해짐**   | 키를 CRC16 해시 후 16384로 나누면 slot 번호가 정해지고, 해당 슬롯이 어떤 노드에 할당되었는지만 알면 노드를 결정할 수 있음 |
| **키 이동 단위가 slot이므로 재배치가 효율적임** | 새로운 노드를 추가할 때, slot 단위로만 이동하면 되므로 데이터 이동이 Consistent Hashing보다 예측 가능하고 안정적    |
| **성능 & 구현이 단순함**               | 고정된 슬롯을 사용하면 노드 간의 라우팅 정보가 작고, 성능상 이점이 큼                                      |
| **failover에 유리**               | slot → master → replica 구조에서 slot 단위 failover가 가능, 재해복구 용이                    |

---

## Q5. HashMap에서 key로 객체를 사용할 때, equals()와 hashCode()는 어떤 역할을 하나요? 그리고 이 두 메서드 중 하나만 재정의했을 때 어떤 문제가 발생할 수 있는지 예를 들어 설명해 주세요.
> hashMap에서 equals는 키에 해당하는 값을 찾는다면 hashCode는 어떤 해시 배치를 찾는 역할을 수행합니다.  
> 둘중 하나라도 잘못 되어있다면, 해시 인덱스를 잘못 찾은 곳에서 equals를 수행해서 데이터를 찾지 못할 수 있습니다.

- hashCode()가 같아야 같은 버킷에 저장
- equals()가 같아야 동일 key로 인식
- 둘 중 하나라도 일관성이 없으면 HashMap은 정상적으로 동작하지 않음

| 메서드            | 역할                                            |
| -------------- | --------------------------------------------- |
| **hashCode()** | 객체가 어떤 **버킷(index)**에 저장될지를 결정하는 해시값을 반환      |
| **equals()**   | 동일한 버킷에 위치한 객체들 중에서, **정확히 어떤 key인지 비교**하여 식별 |

---

## Q6. JPA에서 @Entity 클래스를 HashMap의 key로 사용하는 경우가 있습니다. 이때 equals와 hashCode를 구현할 때 주의할 점은 무엇일까요?
> 동등성(equals) & 해시값(hashCode) 기준을 ID로 두는 것이 일반적입니다. 
> 영속화되기 전, 즉 ID가 null인 상태에서 HashMap에 넣으면 hashCode()는 0이 됩니다.
나중에 persist 되어 ID가 생기면, hashCode가 바뀌기 때문에 HashMap에서 해당 키를 못 찾게 됩니다.

| 항목                 | 설명                                                          |
| ------------------ | ----------------------------------------------------------- |
| equals/hashCode 기준 | 보통 `@Id` (DB 기본키) 기반으로 함                                    |
| 위험한 시점             | 영속화 전 ID가 없는 상태에서 key로 사용하면 안 됨                             |
| 해결 방법              | 영속화 후 사용하거나, business key 기반 equals/hashCode 분리 구현 (복잡함 주의) |


---

## Q7. Java의 HashMap은 내부적으로 배열 + 연결 리스트로 구성되어 있다고 배웠을 텐데요, Java 8 이후에는 어떤 조건에서 연결 리스트 대신 트리(Tree)로 바뀌나요?
> Java 8부터는 버킷 충돌이 심할 경우, 해당 버킷을 LinkedList → Tree (Red-Black Tree)로 변환하여 해시 충돌이 심해져도 성능이 급격히 저하되지 않도록 방어하는 구조로 성능을 개선합니다.

- 조건:
  - 하나의 해시 버킷에 저장되는 엔트리 수가 8개 이상이면 트리로 변환 
  - 단, 배열 크기(capacity)가 64 이상이어야 트리 변환이 적용됨 
    - (작은 해시 테이블에선 오히려 트리화가 성능 저하를 유발할 수 있기 때문)
- 반대로:
  - 버킷에 있는 노드 수가 6개 이하로 줄어들면 다시 LinkedList로 변환

| 구조               | 평균 탐색 시간     |
| ---------------- | ------------ |
| LinkedList       | **O(n)**     |
| Tree (Red-Black) | **O(log n)** |

| 조건             | 설명                      |
| -------------- | ----------------------- |
| 충돌 버킷에 엔트리 ≥ 8 | Red-Black Tree로 변환      |
| 해시 버킷 수 ≥ 64   | 트리 변환 허용 조건             |
| 성능 효과          | 충돌 상황에서도 O(log n) 탐색 보장 |


---

## Q8. 좋은 해시 함수가 가져야 할 특성은 무엇인가요?
> 좋은 해시 함수의 조건은 해시 충돌이 적고, 균등하게 키가 분산되며, 같은 요청에 대해서 항상 같은 해시 값이 반환되는 것을 보장하는 함수입니다.

| 특성                               | 설명                                           |
| -------------------------------- | -------------------------------------------- |
| **균등 분포 (Uniform Distribution)** | 서로 다른 입력값이 해시 테이블의 모든 버킷에 **고르게 분포**되도록 해야 함 |
| **충돌 최소화 (Low Collision Rate)**  | 서로 다른 key가 같은 해시값을 가질 확률이 낮아야 함              |
| **빠른 계산 속도 (Efficiency)**        | 해시 연산이 빨라야 HashMap 전체 성능이 유지됨                |
| **결정성 (Determinism)**            | 같은 입력값에 대해 항상 같은 해시값을 반환해야 함                 |

❌ 나쁜 해시 함수의 결과: 성능 문제
- 많은 키들이 같은 해시값을 가질 경우, 같은 버킷에 몰려들어 충돌 발생
- 충돌이 많으면 결국 버킷 내부 탐색이 O(n) → HashMap 전체 성능이 O(1) → O(n) 으로 악화
- Java 7까지는 LinkedList 기반 버킷이라, 충돌이 심하면 해시 테이블 전체가 느려짐
- Java 8 이후는 트리화되긴 하지만, 트리화 기준 이전까지는 여전히 느림
- 📌 즉, 나쁜 해시 함수 = 좋은 자료구조도 느려지게 만드는 주범입니다.


---

## Q9. Redis에서 Hot Key가 발생하는 원인과 샤딩 처리 방식
> 레디스에서 핫키가 발생하는 원인은 키로 설정된 특정 키에 조회 요청이 많을때 발생되며,  
> 이를 위한 샤딩 처리방식에는 특정 요청에 대한 키 샤딩을 반영하는 방식이 있습니다.

Redis는 단일 스레드 기반이라 특정 키에 집중된 요청이 많을 경우 병목 발생
- 주로: 자주 접근되는 세션 정보 (예: 인기 상품의 조회 수, 로그인 세션)
- 실시간 랭킹/카운터
- 인기 사용자/핫 콘텐츠 관련 캐시

#### 해결 방안 
Key 샤딩 (Key-level Sharding)
- 핫키를 hotKey:1, hotKey:2, ... 처럼 N개의 버전으로 분산 저장
- 읽을 땐 무작위 하나를 읽거나 모든 샤드 값을 평균/합산

Proxy-based Sharding (예: Twemproxy, Codis)
- 클라이언트가 직접 분산 로직을 갖고 샤딩된 여러 Redis에 요청
- 키 수준이 아닌 서버 수준의 병렬 처리 가능

Read Replica 활용
- 핫키 읽기 부하가 클 경우, 읽기 전용 Replica Redis를 두어 Read 분산
- 단, 실시간성이 중요한 경우 복제 지연(latency) 고려 필요

---

## Q9-2. TTL 만료 시 캐시 미스 최소화 전략
> 캐시 미스를 줄이기 위해서 soft ttl을 적용하고 soft ttl 적용기간동안 백그라운드로 캐시를 업데이트할 수 있을 것 같습니다.

#### 해결 전략 
1. Soft TTL + Background Refresh
- Soft TTL은 내부적으로 만료되었지만, 아직 사용 가능한 상태로 간주
- 이 TTL이 지난 시점부터는 요청자는 예전 값을 임시로 제공
- 백그라운드에서 비동기로 최신 데이터로 갱신
2. Request Coalescing
- 여러 스레드가 동시에 캐시 미스를 발생시킬 때, 한 요청만 DB에 접근하고 나머지는 그 결과를 기다림
- 📌 예시:
  - ConcurrentHashMap<String, CompletableFuture<Data>> 같은 구조로 요청을 그룹화
- 📌 장점:
  - 동일 키에 대한 중복 로직 방지
  - 하나의 요청으로 모든 요청 처리 가능
- TTL Jitter 적용
  - 모든 키가 동시에 만료되는 현상 방지 위해 TTL에 무작위 편차(Jitter) 추가

---

## Q10. HashMap의 Resize 시 전체 Rehash가 필요한 이유
> HashMap은 내부적으로 배열의 크기(capacity)를 기준으로 hashCode % capacity로 버킷 인덱스를 정합니다.
그런데 resize가 발생하면 따라서 기존 key들의 bucket index도 바뀔 수밖에 없기 때문에, 모든 key의 hash 재계산이 필요합니다.
즉, 단순히 배열 크기만 키우는 게 아니라, 모든 key를 새 배열에 재배치(rehash) 해야 합니다.

| 항목              | 설명                                                                           |
| --------------- | ---------------------------------------------------------------------------- |
| **CPU 부하**      | 모든 key에 대해 hash 연산 + 이동 → 순간적인 성능 저하 가능                                      |
| **GC Pressure** | 많은 객체 재배치 → GC pause 유발 가능                                                   |
| **스레드 경쟁**      | 동시성 환경에서는 resize가 스레드 경쟁을 유발할 수 있음 (Java 7의 `HashMap`은 리사이징 중 무한 루프 버그도 있었음) |

### 💥 실무에서 문제가 되는 시나리오
#### 초기에 capacity를 작게 설정한 HashMap을 고속으로 insert 하게 되면, 리사이징이 여러 번 발생 → latency 급증
- 예시 상황
  - Spring Batch 처리 중 대량의 데이터를 Map에 누적할 때
  - Kafka consumer가 in-memory aggregation 할 때
  - Redis key 동기화 작업 중 로컬에 데이터를 해시맵으로 임시 보관할 때
#### 해결 방법
- 초기 capacity와 loadFactor를 적절히 설정 (기본 loadFactor는 0.75)
- 예상되는 데이터 수보다 살짝 큰 초기 capacity를 지정하면 resize를 줄일 수 있음


---

## Q11. Redis Hash와 Java HashMap의 근본적 차이
> 둘 다 key-value 쌍을 저장하는 해시 자료구조 내부적으로 버킷에 key를 매핑해 빠른 조회를 지원하지만,    
> Java에서는 로컬메모리 기반으로 세션 정보를 저장했다면,
> Redis에서는 분산 환경, 세션 캐싱, 공유 상태 저장을 지원합니다. 

| 항목            | Redis Hash                                    | Java HashMap                         |
| ------------- | --------------------------------------------- | ------------------------------------ |
| **저장 위치**     | 네트워크로 접근하는 **인메모리 서버**                        | **JVM 내부 메모리**                       |
| **사용 목적**     | 분산 환경에서의 **데이터 공유 및 캐싱**                      | 로컬 프로세스 내 **단기 데이터 구조**              |
| **접근 비용**     | 네트워크 비용 있음 (RTT 포함)                           | 거의 O(1) 성능                           |
| **직렬화 필요 여부** | key/value 모두 문자열 혹은 직렬화 필요                    | Java 객체 그대로 사용 가능                    |
| **자료구조 유연성**  | Redis는 다양한 자료구조 제공 (`hash`, `zset`, `list` 등) | 일반적으로 해시만                            |
| **멀티스레드**     | Redis는 단일 스레드 → race condition 방지             | Java는 멀티스레드 → ConcurrentHashMap 등 필요 |
| **메모리 관리**    | Redis는 자체 메모리 정책 사용 (e.g., maxmemory)         | GC 영향 직접 받음                          |


---

## Q12. HashMap / ConcurrentHashMap / LinkedHashMap 선택 기준
| 자료구조                  | 주요 특성                            | 사용 예시                        |
| --------------------- | -------------------------------- | ---------------------------- |
| **HashMap**           | 비동기 환경에서 안전하지 않음<br>빠른 읽기/쓰기 성능  | 단일 스레드 환경 또는 동시 접근이 없는 임시 캐시 |
| **ConcurrentHashMap** | 스레드 안전, 세그먼트 락/버킷 락 등으로 락 경합 최소화 | 멀티 스레드 환경의 공유 캐시, 비즈니스 상태 저장 |
| **LinkedHashMap**     | 입력 순서 또는 LRU 순서를 유지<br>정렬된 순회 가능 | 순서를 유지하는 캐시, LRU 알고리즘 구현 등   |
